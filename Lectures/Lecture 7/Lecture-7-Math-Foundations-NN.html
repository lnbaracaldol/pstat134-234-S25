<!DOCTYPE html>
<html lang="en"><head>
<script src="Lecture-7-Math-Foundations-NN_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lecture-7-Math-Foundations-NN_files/libs/quarto-html/tabby.min.js"></script>
<script src="Lecture-7-Math-Foundations-NN_files/libs/quarto-html/popper.min.js"></script>
<script src="Lecture-7-Math-Foundations-NN_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Lecture-7-Math-Foundations-NN_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lecture-7-Math-Foundations-NN_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Lecture-7-Math-Foundations-NN_files/libs/quarto-html/quarto-syntax-highlighting-de84f8d6bb715db06a919283c2d1e787.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <title>Mathematical Foundations of Neural Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/dist/theme/quarto-8f3eebe07241f08526c91a7e9cbef8fd.css">
  <link rel="stylesheet" href="lec2.css">
  <link href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Mathematical Foundations of Neural Networks</h1>

<div class="quarto-title-authors">
</div>

</section>
<section class="slide level2">

<!-- # Lecture Overview {data-background-transition="fade"} -->
<!-- - **Sections:** -->
<!--   1. Motivation & History (10′) -->
<!--   2. Linear Models Review (15′) -->
<!--   3. Perceptron & Activation Functions (20′) -->
<!--   4. Loss Functions (15′) -->
<!--   5. R vs Python Demo (15′) -->
</section>
<section id="classical-programming-vs.-machine-learning" class="slide level2" data-background="light">
<h2>Classical Programming vs.&nbsp;Machine Learning</h2>
<div class="columns">
<div class="column">
<p><strong>Classical Programming</strong><br>
- Humans write explicit rules (code)<br>
- Program + Input → Deterministic Output<br>
- To change behavior, you must edit the code</p>
<p><strong>Machine Learning</strong><br>
- Algorithms infer rules from data examples<br>
- Input + Target Outputs → Learned Model<br>
- To improve behavior, you retrain on new data</p>
</div><div class="column">
<p><img data-src="img/ml.png" style="width:90.0%"></p>
</div></div>
</section>
<section id="learning-rules-representations" class="slide level2" data-background="light">
<h2>Learning Rules &amp; Representations</h2>
<p><span class="math display">\[
\mathbf{y} = f(\mathbf{x};\,\theta),\quad f \in \mathcal{H}
\]</span></p>
<ul>
<li class="fragment"><p><strong>Data:</strong> <span class="math inline">\(\{(\mathbf{x}_i,\mathbf{y}_i)\}_{i=1}^n\)</span></p>
<p>– <span class="math inline">\(\mathbf{x}_i\)</span>: input<br>
– <span class="math inline">\(\mathbf{y}_i\)</span>: output</p></li>
<li class="fragment"><p><strong>Hypothesis space:</strong> <span class="math inline">\(\mathcal{H}\)</span>, A predefined set of candidate functions <span class="math inline">\(f\)</span></p></li>
<li class="fragment"><p><strong>Loss function:</strong> Measures error between prediction and target: <span class="math inline">\(L\bigl(f(\mathbf{x}_i;\theta),\,\mathbf{y}_i\bigr)\)</span></p></li>
<li class="fragment"><p><strong>Learning rule:</strong> <span class="math inline">\(\theta^* =\arg\min_{\theta}\;\sum_{i=1}^n L\bigl(f(\mathbf{x}_i;\theta),\,\mathbf{y}_i\bigr)\)</span></p></li>
<li class="fragment"><p><strong>Representation learning:</strong> <span class="math inline">\(f\)</span> automatically maps raw <span class="math inline">\(\mathbf{x}\)</span> through successive transformations into features that make predicting <span class="math inline">\(\mathbf{y}\)</span> easier.</p></li>
</ul>
</section>
<section id="history-of-ml-predeep-learning" class="slide level2" data-background="light">
<h2>History of ML (Pre–Deep Learning)</h2>
<p>Machine learning before the 2010s featured “shallow” methods that relied on hand‐crafted features and smaller models. Key paradigms include:</p>
<ol type="1">
<li class="fragment">Probabilistic Modeling<br>
</li>
<li class="fragment">Early Neural Networks<br>
</li>
<li class="fragment">Kernel Methods<br>
</li>
<li class="fragment">Trees &amp; Ensembles</li>
</ol>
</section>
<section id="probabilistic-models" class="slide level2" data-background="light">
<h2>Probabilistic Models</h2>
<div style="font-size: 0.9em">
<ul>
<li class="fragment"><p>Applies statistical principles</p></li>
<li class="fragment"><p><em>Model specification:</em> <span class="math inline">\(p(\mathbf{x},y;\,\theta)\)</span> (joint distribution over <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(y\)</span>)</p></li>
<li class="fragment"><p><strong>Maximum Likelihood Estimation (MLE)</strong><br>
<span class="math display">\[\hat\theta_{\text{MLE}}
  = \arg\max_{\theta}\;\prod_{i=1}^n p(\mathbf{x}_i,y_i;\theta)
  = \arg\max_{\theta}\;\sum_{i=1}^n \log p(\mathbf{x}_i,y_i;\theta)
\]</span></p></li>
<li class="fragment"><p><strong>Bayesian Inference (MAP &amp; Posterior)</strong> <span class="math inline">\(p(\theta\mid y)\propto p(y\mid\theta)\,p(\theta), \quad \hat\theta_{\text{MAP}} = \arg\max_{\theta}\;p(\theta\mid y)\)</span></p></li>
<li class="fragment"><p>Examples:</p>
<ul>
<li class="fragment"><strong>Naive Bayes</strong>: input features are conditionally independent given the class</li>
<li class="fragment"><strong>Logistic Regression</strong>: Binary classifier</li>
<li class="fragment"><strong>Bayesian linear regression</strong>.</li>
</ul></li>
</ul>
</div>
</section>
<section id="early-nural-nets" class="slide level2">
<h2>Early Nural Nets</h2>
<ul>
<li class="fragment">1950s perceptrons: Binary linear classifier.
<ul>
<li class="fragment"><p><strong>Model &amp; Decision</strong> <span class="math inline">\(a = w^\top x + b,\quad \hat y = \operatorname{sign}(a),\quad\text{boundary: }w^\top x + b = 0\)</span></p></li>
<li class="fragment"><p><strong>Learning Rule</strong>: Shifts the hyperplane toward misclassified points. For each misclassified <span class="math inline">\(((x_i,y_i)\)</span>, update with learning rate <span class="math inline">\(\eta\)</span>: <span class="math display">\[
w \;\gets\; w + \eta\,y_i\,x_i,\quad
b \;\gets\; b + \eta\,y_i
\]</span></p></li>
<li class="fragment"><p><strong>Properties</strong></p>
<ul>
<li class="fragment">Converges in finite steps if data are linearly separable<br>
</li>
<li class="fragment">Cannot solve non‐linearly separable tasks (e.g.&nbsp;XOR)</li>
</ul></li>
</ul></li>
<li class="fragment"><strong>LeNet (1989)</strong>: first practical CNN for digit recognition</li>
</ul>
</section>
<section id="kernel-methods-1990s" class="slide level2" data-background="light">
<h2>Kernel Methods (1990s)</h2>
<ul>
<li class="fragment">Map data into high-dimensional spaces for linear separation<br>
</li>
<li class="fragment"><strong>Support Vector Machines (SVMs)</strong>
<ol type="1">
<li class="fragment">Implicit feature mapping via <strong>kernel trick</strong><br>
</li>
<li class="fragment">Maximize margin between classes<br>
</li>
</ol></li>
<li class="fragment">Strengths: strong theory, interpretable<br>
</li>
<li class="fragment">Limitations: poor scalability, need hand‐crafted features</li>
</ul>
</section>
<section id="trees-ensemble-methods-2000s" class="slide level2" data-background="light">
<h2>Trees &amp; Ensemble Methods (2000s)</h2>
<div style="font-size: 0.85em">
<p><strong>Decision Trees</strong></p>
<ul>
<li class="fragment">Recursive partitioning of feature space via splits<br>
</li>
<li class="fragment">Fast to train and interpret, but high variance</li>
</ul>
<p><strong>Random Forests</strong></p>
<ul>
<li class="fragment">Ensemble of <span class="math inline">\(B\)</span> trees on bootstrap samples. <span class="math display">\[\hat y =
  \begin{cases}
    \text{majority vote (classification)}\\
    \frac{1}{B}\sum_{b=1}^B T_b(x)\ \text{(regression)}
  \end{cases}\]</span><br>
</li>
<li class="fragment">Reduces variance and overfitting</li>
</ul>
<p><strong>Gradient Boosting Machines</strong></p>
<ul>
<li class="fragment">Sequentially train trees to correct errors: Each tree <span class="math inline">\(h_m\)</span> fits residuals <span class="math inline">\(r_i^{(m)}=y_i - F_{m-1}(x_i)\)</span></li>
</ul>
</div>
</section>
<section id="why-deep-learning" class="slide level2" data-background="light">
<h2>Why Deep Learning?</h2>
<ul>
<li class="fragment"><p><strong>Automatic feature learning</strong><br>
Learns representations directly from raw data—no hand-crafted features needed.</p></li>
<li class="fragment"><p><strong>Hierarchical abstraction</strong><br>
Captures low-level to high-level patterns through successive layers.</p></li>
<li class="fragment"><p><strong>Scalability</strong><br>
Leverages large datasets and modern hardware (GPUs) for better performance.</p></li>
<li class="fragment"><p><strong>End-to-end optimization</strong><br>
Trains all components jointly to directly minimize task loss.</p></li>
<li class="fragment"><p><strong>Superior on unstructured data</strong><br>
Sets state-of-the-art in vision, speech, NLP, and more.</p></li>
<li class="fragment"><p><strong>Transfer learning</strong><br>
Fine-tune pretrained deep models to new domains with limited data.</p></li>
</ul>
</section>
<section id="achievements-of-deep-learning" class="slide level2" data-background="light">
<h2>Achievements of Deep Learning</h2>
<ul>
<li class="fragment"><strong>Perception &amp; Recognition</strong>
<ul>
<li class="fragment">Near-human image classification<br>
</li>
<li class="fragment">Near-human speech &amp; handwriting transcription</li>
</ul></li>
<li class="fragment"><strong>Language &amp; Dialogue</strong>
<ul>
<li class="fragment">Dramatic gains in machine translation &amp; text-to-speech<br>
</li>
<li class="fragment">Digital assistants (Google Assistant, Alexa)<br>
</li>
<li class="fragment">Ability to answer natural-language questions</li>
</ul></li>
<li class="fragment"><strong>Autonomy &amp; Games</strong>
<ul>
<li class="fragment">Near-human autonomous driving<br>
</li>
<li class="fragment">Superhuman performance in Go</li>
</ul></li>
</ul>
</section>
<section id="deep-learning-hierarchical-representation-learning" class="slide level2" data-background="light">
<h2>Deep Learning: Hierarchical Representation Learning</h2>
<ul>
<li class="fragment"><strong>Subfield of ML</strong> that learns <strong>successive layers</strong> of representations<br>
</li>
<li class="fragment"><strong>“Deep”</strong> = many successive layers of parameterized functions (depth = number of layers)<br>
</li>
<li class="fragment">Modern models use <strong>tens–hundreds</strong> of layers, all learned from data<br>
</li>
<li class="fragment"><strong>Shallow learning</strong> uses only 1–2 layers (e.g.&nbsp;feature extractor + classifier)<br>
</li>
<li class="fragment">Implemented via <strong>neural networks</strong>: literal stacks of parameterized layers<br>
</li>
<li class="fragment">Model as function composition: <span class="math display">\[
  h^{(1)} = f^{(1)}(x;W^{(1)}),\
  h^{(2)} = f^{(2)}(h^{(1)};W^{(2)}),\ \dots,\
  \hat y = f^{(L)}(h^{(L-1)};W^{(L)})
\]</span></li>
</ul>
</section>
<section id="deep-learning-hierarchical-representation-learning-1" class="slide level2" data-background="light">
<h2>Deep Learning: Hierarchical Representation Learning</h2>
<blockquote>
<p>You can think of a deep network as a multistage information- distillation process, where information goes through successive filters and comes out increasingly purified</p>
</blockquote>

<img data-src="img/NN.png" style="width:80.0%" class="r-stretch"></section>
<section id="feedforward-neural-networks" class="slide level2" data-background="light">
<h2>Feedforward Neural Networks</h2>
<ul>
<li class="fragment"><p><strong>Definition</strong><br>
A feedforward neural network (FNN) is a directed acyclic graph of layers that maps inputs <span class="math inline">\(\mathbf{x}\)</span> to outputs <span class="math inline">\(\hat{\mathbf{y}}\)</span> without cycles or recurrent connections.</p></li>
<li class="fragment"><p><strong>Architecture</strong><br>
<span class="math display">\[
  \mathbf{x} \;\longrightarrow\;
  \underbrace{\bigl[h^{(1)},\,h^{(2)},\,\dots,h^{(L-1)}\bigr]}_{\text{hidden layers}}
  \;\longrightarrow\; \hat{\mathbf{y}}
\]</span></p>
<ul>
<li class="fragment"><strong>Input layer</strong>: raw features<br>
</li>
<li class="fragment"><strong>Hidden layers</strong>: one or more fully-connected layers<br>
</li>
<li class="fragment"><strong>Output layer</strong>: predictions</li>
</ul></li>
</ul>
</section>
<section id="feedforward-neural-networks-1" class="slide level2" data-background="light">
<h2>Feedforward Neural Networks</h2>
<ul>
<li class="fragment"><strong>Layer computation</strong><br>
For layer <span class="math inline">\(l=1,\dots,L\)</span>: <span class="math display">\[
h^{(l)} = \sigma^{(l)}\bigl(a^{(l)}\bigr)\\
  a^{(l)} = W^{(l)}\,h^{(l-1)} + b^{(l)}
\]</span> with <span class="math inline">\(h^{(0)} = \mathbf{x}\)</span> and <span class="math inline">\(\hat{\mathbf{y}}=h^{(L)}\)</span>, <span class="math inline">\(\sigma^{(l)}\)</span>: Activation function</li>
</ul>

<img data-src="img/Forward.png" style="width:60.0%" class="r-stretch"></section>
<section id="activation-functions" class="slide level2">
<h2>Activation Functions</h2>
<div class="columns">
<div class="column">
<ul>
<li class="fragment"><p><strong>Linear (Identity):</strong> <span class="math inline">\(f(a) = a\)</span> <!-- - Derivative:  $f'(a) = 1$ --></p></li>
<li class="fragment"><p><strong>ReLU:</strong> <span class="math inline">\(\mathrm{ReLU}(a)=\max(0,a)\)</span> <!-- - Derivative: $\mathbf{1}_{a>0}$ --></p></li>
<li class="fragment"><p><strong>Sigmoid:</strong> <span class="math inline">\(\sigma(a)=\frac{1}{1+e^{-a}}\)</span> <!-- - Derivative: $\sigma(a)(1-\sigma(a))$ --></p></li>
<li class="fragment"><p><strong>Softmax (multi‐class):</strong> <span class="math inline">\(\mathrm{softmax}(z)_i = \frac{\exp(z_i)}{\sum_{j=1}^K \exp(z_j)},\quad i=1\dots K\)</span> <!-- - Jacobian: $\frac{\partial p_i}{\partial z_j} = p_i(\delta_{ij}-p_j)$ --></p></li>
</ul>
</div><div class="column">
<p><img data-src="img/act2.png" style="width:85.0%"></p>
</div></div>
</section>
<section id="activation-function-output-layer" class="slide level2">
<h2>Activation Function (output layer)</h2>

<img data-src="img/act.png" style="width:60.0%" class="r-stretch"></section>
<section id="loss-function" class="slide level2" data-background="light">
<h2>Loss Function</h2>
<div class="columns">
<div class="column">
<p>The <strong>loss function</strong> (aka objective or cost) measures how far a network’s prediction <span class="math inline">\(\hat y\)</span> is from the true target <span class="math inline">\(y\)</span>for a single example:</p>
<p><span class="math display">\[
L\bigl(\hat y,\,y\bigr)
\;\longrightarrow\;
\text{distance score}
\]</span></p>
<p>This score is used as a feedback signal to adjust the network’s weights during training.</p>
</div><div class="column">
<p><img data-src="img/loss.png" style="width:80.0%"></p>
</div></div>
</section>
<section id="loss-functions" class="slide level2" data-background="light">
<h2>Loss Functions</h2>
<h3 id="mean-squared-error-regression">Mean Squared Error (Regression)</h3>
<p><span class="math inline">\(\mathrm{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat y_i)^2\)</span></p>
<!-- Gradient wrt pre‐activation (linear output): $\frac{\partial L}{\partial a_i} = \frac{2}{n} (\hat y_i - y_i)$ -->
<h3 id="crossentropy-classification">Cross‐Entropy (Classification)</h3>
<ul>
<li class="fragment"><p><strong>Binary CE:</strong> <span class="math inline">\(L = -\frac{1}{n}\sum_{i=1}^n [y_i\log(p_i) + (1-y_i)\log(1-p_i)]\)</span></p>
<!-- $frac{\partial L}{\partial a_i} = \frac{1}{n}(p_i - y_i)$ --></li>
<li class="fragment"><p><strong>Categorical CE:</strong> <span class="math inline">\(L = -\frac{1}{n}\sum_{i=1}^n \sum_{c=1}^K y_{i,c}\log(p_{i,c})\)</span></p></li>
</ul>
</section>
<section id="training-of-a-nn" class="slide level2" data-background="light">
<h2>Training of a NN</h2>
<ul>
<li class="fragment"><strong>Feedback signal:</strong> use the loss <span class="math inline">\(L(\hat y,y)\)</span> to quantify error<br>
</li>
<li class="fragment"><strong>Optimizer’s job:</strong> adjust each weight to reduce the loss</li>
</ul>

<img data-src="img/back.png" style="width:50.0%" class="r-stretch"></section>
<section id="training-via-backpropagation" class="slide level2" data-background="light">
<h2>Training via backpropagation</h2>
<ol type="1">
<li class="fragment">Initialize <span class="math inline">\(W^{(l)}\)</span> randomly<br>
</li>
<li class="fragment">Forward pass → compute <span class="math inline">\(\hat y\)</span><br>
</li>
<li class="fragment">Compute loss <span class="math inline">\(L(\hat y,y)\)</span><br>
</li>
<li class="fragment">Backward pass → <span class="math inline">\(\frac{\partial L}{\partial W^{(l)}}\)</span><br>
</li>
<li class="fragment">Update: <span class="math inline">\(W^{(l)} \leftarrow W^{(l)} - \eta\frac{\partial L}{\partial W^{(l)}}\)</span> (gradient descent)</li>
<li class="fragment">Repeat over epochs until convergence</li>
</ol>
</section>
<section id="linear-models-review" class="slide level2" data-background="light">
<h2>Linear Models Review</h2>
<ul>
<li class="fragment"><p><strong>Scalar form:</strong> <span class="math inline">\(y = w_1 x_1 + \dots + w_p x_p + b\)</span></p></li>
<li class="fragment"><p><strong>Vector form:</strong> <span class="math inline">\(y = w^T x + b,\quad w,x \in \mathbb{R}^p,\ b\in \mathbb{R}\)</span></p></li>
<li class="fragment"><p><strong>Matrix form (batch):</strong> <span class="math inline">\(Y = XW + \mathbf{b},\)</span></p>
<p>where:</p>
<ul>
<li class="fragment"><span class="math inline">\(X \in \mathbb{R}^{n    \times p}\)</span> (samples × features)</li>
<li class="fragment"><span class="math inline">\(W \in \mathbb{R}^{p    \times 1}\)</span> (features × outputs)</li>
<li class="fragment"><span class="math inline">\(\mathbf{b}\in\mathbb{R}^{n \times 1}\)</span></li>
</ul></li>
<li class="fragment"><p><strong>Gradients:</strong></p>
<p><span class="math display">\[\frac{\partial L}{\partial W} \propto X^T ( \hat Y - Y ),\quad \frac{\partial L}{\partial b} \propto \sum_{i=1}^n (\hat y_i - y_i)\]</span></p></li>
</ul>
</section>
<section id="gradient-descent-algorithm-in-python" class="slide level2">
<h2>Gradient descent algorithm in Python</h2>
<div id="2d3a3e98" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="co"># Gradient Descent from Scratch for y = w·x + b</span></span>
<span id="cb1-2"><a href=""></a><span class="im">import</span> random</span>
<span id="cb1-3"><a href=""></a>p <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-4"><a href=""></a>true_w <span class="op">=</span> [<span class="fl">2.5</span>, <span class="op">-</span><span class="fl">1.0</span>]</span>
<span id="cb1-5"><a href=""></a>true_b <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb1-6"><a href=""></a>sigma <span class="op">=</span> <span class="fl">1.0</span>   </span>
<span id="cb1-7"><a href=""></a></span>
<span id="cb1-8"><a href=""></a><span class="co">### Generate n samples</span></span>
<span id="cb1-9"><a href=""></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb1-10"><a href=""></a>X <span class="op">=</span> [[random.uniform(<span class="dv">0</span>, <span class="dv">5</span>) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(p)] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb1-11"><a href=""></a></span>
<span id="cb1-12"><a href=""></a><span class="co">##### Make y = w·x + b + ε,</span></span>
<span id="cb1-13"><a href=""></a>Y <span class="op">=</span> []</span>
<span id="cb1-14"><a href=""></a><span class="cf">for</span> xi <span class="kw">in</span> X:</span>
<span id="cb1-15"><a href=""></a>    noise <span class="op">=</span> random.gauss(<span class="dv">0</span>, sigma)</span>
<span id="cb1-16"><a href=""></a>    y <span class="op">=</span> <span class="bu">sum</span>(true_w[j] <span class="op">*</span> xi[j] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(p)) <span class="op">+</span> true_b <span class="op">+</span> noise</span>
<span id="cb1-17"><a href=""></a>    Y.append(y)</span>
<span id="cb1-18"><a href=""></a></span>
<span id="cb1-19"><a href=""></a>w <span class="op">=</span> [random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(p)]</span>
<span id="cb1-20"><a href=""></a>b <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-21"><a href=""></a></span>
<span id="cb1-22"><a href=""></a><span class="co">###  Hyperparameters</span></span>
<span id="cb1-23"><a href=""></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">;</span>n_iters <span class="op">=</span> <span class="dv">1000</span><span class="op">;</span>n <span class="op">=</span> <span class="bu">len</span>(X)</span>
<span id="cb1-24"><a href=""></a><span class="co">###  Training loop</span></span>
<span id="cb1-25"><a href=""></a><span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(n_iters):</span>
<span id="cb1-26"><a href=""></a>    <span class="co">#  Compute predictions and residuals</span></span>
<span id="cb1-27"><a href=""></a>    Y_hat <span class="op">=</span> []</span>
<span id="cb1-28"><a href=""></a>    <span class="cf">for</span> xi <span class="kw">in</span> X:</span>
<span id="cb1-29"><a href=""></a>        pred <span class="op">=</span> <span class="bu">sum</span>(w[j] <span class="op">*</span> xi[j] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(p)) <span class="op">+</span> b</span>
<span id="cb1-30"><a href=""></a>        Y_hat.append(pred)</span>
<span id="cb1-31"><a href=""></a>    residuals <span class="op">=</span> [Y_hat[i] <span class="op">-</span> Y[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb1-32"><a href=""></a>    </span>
<span id="cb1-33"><a href=""></a>    <span class="co"># </span><span class="al">###</span><span class="co"> Compute gradients</span></span>
<span id="cb1-34"><a href=""></a>    <span class="co">#    ∂L/∂w_j = (1/n) * Σ_i [ residuals_i * x_i_j ]</span></span>
<span id="cb1-35"><a href=""></a>    <span class="co">#    ∂L/∂b   = (1/n) * Σ_i [ residuals_i ]</span></span>
<span id="cb1-36"><a href=""></a>    grad_w <span class="op">=</span> [<span class="fl">0.0</span>] <span class="op">*</span> p</span>
<span id="cb1-37"><a href=""></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(p):</span>
<span id="cb1-38"><a href=""></a>        grad_w[j] <span class="op">=</span> <span class="bu">sum</span>(residuals[i] <span class="op">*</span> X[i][j] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)) <span class="op">/</span> n</span>
<span id="cb1-39"><a href=""></a>    grad_b <span class="op">=</span> <span class="bu">sum</span>(residuals) <span class="op">/</span> n</span>
<span id="cb1-40"><a href=""></a></span>
<span id="cb1-41"><a href=""></a>    <span class="co">####Update parameters</span></span>
<span id="cb1-42"><a href=""></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(p):</span>
<span id="cb1-43"><a href=""></a>        w[j] <span class="op">-=</span> learning_rate <span class="op">*</span> grad_w[j]</span>
<span id="cb1-44"><a href=""></a>    b <span class="op">-=</span> learning_rate <span class="op">*</span> grad_b</span>
<span id="cb1-45"><a href=""></a></span>
<span id="cb1-46"><a href=""></a>    <span class="co">### Compute and print loss every 100 iters</span></span>
<span id="cb1-47"><a href=""></a>    <span class="cf">if</span> it <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb1-48"><a href=""></a>        loss <span class="op">=</span> <span class="bu">sum</span>(r<span class="op">**</span><span class="dv">2</span> <span class="cf">for</span> r <span class="kw">in</span> residuals) <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>n)</span>
<span id="cb1-49"><a href=""></a>        <span class="bu">print</span>(<span class="ss">f"Iter </span><span class="sc">{</span>it<span class="sc">:4d}</span><span class="ss"> | Loss: </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb1-50"><a href=""></a></span>
<span id="cb1-51"><a href=""></a><span class="co">######Final parameters</span></span>
<span id="cb1-52"><a href=""></a><span class="bu">print</span>(<span class="st">"Learned weights:"</span>, w)</span>
<span id="cb1-53"><a href=""></a><span class="bu">print</span>(<span class="st">"Learned bias:   "</span>, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Iter    0 | Loss: 17.6226
Iter  100 | Loss: 0.5982
Iter  200 | Loss: 0.5002
Iter  300 | Loss: 0.4988
Iter  400 | Loss: 0.4986
Iter  500 | Loss: 0.4985
Iter  600 | Loss: 0.4985
Iter  700 | Loss: 0.4984
Iter  800 | Loss: 0.4984
Iter  900 | Loss: 0.4984
Learned weights: [2.52683867723346, -0.9740439619681978]
Learned bias:    0.3634387735717077</code></pre>
</div>
</div>
<!-- ## Binary Classificattion: R vs Python Demo {data-background="light"} -->
<!-- ###  R (keras): Single‐Layer Perceptron -->
<!-- ```{r} -->
<!-- library(keras) -->
<!-- # OR truth table -->
<!-- dat <- list( -->
<!--   x = matrix(c(0,0,0,1,1,0,1,1), ncol=2, byrow=TRUE), -->
<!--   y = c(0,1,1,1) -->
<!-- ) -->
<!-- model <- keras_model_sequential() %>% -->
<!--   layer_dense(units=1, input_shape=2, activation='sigmoid') -->
<!-- model %>% compile( -->
<!--   optimizer = optimizer_sgd(), -->
<!--   loss = 'binary_crossentropy', -->
<!--   metrics = 'accuracy' -->
<!-- ) -->
<!-- model %>% fit(dat$x, dat$y, epochs=100, verbose=0) -->
<!-- print(model %>% predict(dat$x)) -->
<!-- ``` -->
</section>
<section id="binary-classificattion-python-demo-tensorflow" class="slide level2">
<h2>Binary Classificattion: Python Demo (TensorFlow)</h2>
<div id="c98197db" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href=""></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href=""></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-3"><a href=""></a></span>
<span id="cb3-4"><a href=""></a><span class="co"># OR dataset</span></span>
<span id="cb3-5"><a href=""></a>X <span class="op">=</span> np.array([[<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb3-6"><a href=""></a>              [<span class="dv">0</span>,<span class="dv">1</span>],</span>
<span id="cb3-7"><a href=""></a>              [<span class="dv">1</span>,<span class="dv">0</span>],</span>
<span id="cb3-8"><a href=""></a>              [<span class="dv">1</span>,<span class="dv">1</span>]], dtype<span class="op">=</span>np.float32)</span>
<span id="cb3-9"><a href=""></a>y <span class="op">=</span> np.array([[<span class="dv">0</span>],</span>
<span id="cb3-10"><a href=""></a>              [<span class="dv">1</span>],</span>
<span id="cb3-11"><a href=""></a>              [<span class="dv">1</span>],</span>
<span id="cb3-12"><a href=""></a>              [<span class="dv">1</span>]], dtype<span class="op">=</span>np.float32)</span>
<span id="cb3-13"><a href=""></a></span>
<span id="cb3-14"><a href=""></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb3-15"><a href=""></a>    tf.keras.Input(shape<span class="op">=</span>(<span class="dv">2</span>,)),              </span>
<span id="cb3-16"><a href=""></a>    tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)</span>
<span id="cb3-17"><a href=""></a>])</span>
<span id="cb3-18"><a href=""></a></span>
<span id="cb3-19"><a href=""></a>model.<span class="bu">compile</span>(</span>
<span id="cb3-20"><a href=""></a>    optimizer<span class="op">=</span>tf.keras.optimizers.SGD(learning_rate<span class="op">=</span><span class="fl">1.0</span>),</span>
<span id="cb3-21"><a href=""></a>    loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb3-22"><a href=""></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb3-23"><a href=""></a>)</span>
<span id="cb3-24"><a href=""></a></span>
<span id="cb3-25"><a href=""></a>history <span class="op">=</span> model.fit(X, y, epochs<span class="op">=</span><span class="dv">1000</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-26"><a href=""></a></span>
<span id="cb3-27"><a href=""></a><span class="co"># final loss &amp; acc</span></span>
<span id="cb3-28"><a href=""></a>final_loss, final_acc <span class="op">=</span> history.history[<span class="st">'loss'</span>][<span class="op">-</span><span class="dv">1</span>], history.history[<span class="st">'accuracy'</span>][<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb3-29"><a href=""></a><span class="bu">print</span>(<span class="ss">f"loss=</span><span class="sc">{</span>final_loss<span class="sc">:.4f}</span><span class="ss">, accuracy=</span><span class="sc">{</span>final_acc<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb3-30"><a href=""></a></span>
<span id="cb3-31"><a href=""></a><span class="co"># probabilities</span></span>
<span id="cb3-32"><a href=""></a>probs <span class="op">=</span> model.predict(X)</span>
<span id="cb3-33"><a href=""></a><span class="bu">print</span>(<span class="st">"probs:</span><span class="ch">\n</span><span class="st">"</span>, probs.T)</span>
<span id="cb3-34"><a href=""></a></span>
<span id="cb3-35"><a href=""></a><span class="co"># hard predictions</span></span>
<span id="cb3-36"><a href=""></a>preds <span class="op">=</span> (probs <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb3-37"><a href=""></a><span class="bu">print</span>(<span class="st">"preds:</span><span class="ch">\n</span><span class="st">"</span>, preds.T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>loss=0.0093, accuracy=1.000
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step
probs:
 [[0.02039506 0.9918514  0.99185723 0.99999857]]
preds:
 [[0 1 1 1]]</code></pre>
</div>
</div>
</section>
<section id="python-pytorch" class="slide level2">
<h2>Python (PyTorch)</h2>
<div id="835cb03d" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href=""></a><span class="co"># PyTorch example</span></span>
<span id="cb5-2"><a href=""></a><span class="im">import</span> torch</span>
<span id="cb5-3"><a href=""></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb5-4"><a href=""></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb5-5"><a href=""></a></span>
<span id="cb5-6"><a href=""></a>X <span class="op">=</span> torch.tensor([[<span class="dv">0</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">1</span>,<span class="dv">1</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb5-7"><a href=""></a>y <span class="op">=</span> torch.tensor([[<span class="dv">0</span>],[<span class="dv">1</span>],[<span class="dv">1</span>],[<span class="dv">1</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb5-8"><a href=""></a></span>
<span id="cb5-9"><a href=""></a><span class="kw">class</span> FNN(nn.Module):</span>
<span id="cb5-10"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb5-11"><a href=""></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-12"><a href=""></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb5-13"><a href=""></a>        <span class="va">self</span>.act <span class="op">=</span> nn.Sigmoid()</span>
<span id="cb5-14"><a href=""></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-15"><a href=""></a>        <span class="cf">return</span> <span class="va">self</span>.act(<span class="va">self</span>.linear(x))</span>
<span id="cb5-16"><a href=""></a></span>
<span id="cb5-17"><a href=""></a>model <span class="op">=</span> FNN()</span>
<span id="cb5-18"><a href=""></a>criterion <span class="op">=</span> nn.BCELoss()</span>
<span id="cb5-19"><a href=""></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-20"><a href=""></a></span>
<span id="cb5-21"><a href=""></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb5-22"><a href=""></a>    optimizer.zero_grad()</span>
<span id="cb5-23"><a href=""></a>    outputs <span class="op">=</span> model(X)</span>
<span id="cb5-24"><a href=""></a>    loss <span class="op">=</span> criterion(outputs, y)</span>
<span id="cb5-25"><a href=""></a>    loss.backward()</span>
<span id="cb5-26"><a href=""></a>    optimizer.step()</span>
<span id="cb5-27"><a href=""></a></span>
<span id="cb5-28"><a href=""></a>out <span class="op">=</span> model(X)           </span>
<span id="cb5-29"><a href=""></a>probs <span class="op">=</span> out.detach().numpy()</span>
<span id="cb5-30"><a href=""></a></span>
<span id="cb5-31"><a href=""></a>preds <span class="op">=</span> (probs <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb5-32"><a href=""></a></span>
<span id="cb5-33"><a href=""></a></span>
<span id="cb5-34"><a href=""></a><span class="bu">print</span>(<span class="st">"Probabilities:</span><span class="ch">\n</span><span class="st">"</span>, probs.T)</span>
<span id="cb5-35"><a href=""></a><span class="bu">print</span>(<span class="st">"Predicted classes:</span><span class="ch">\n</span><span class="st">"</span>, preds.T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Probabilities:
 [[0.17507716 0.93117714 0.93246305 0.9988651 ]]
Predicted classes:
 [[0 1 1 1]]</code></pre>
</div>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Lecture-7-Math-Foundations-NN_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>